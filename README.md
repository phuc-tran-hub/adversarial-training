# adversarial-training

Project Description: This project demonstrates adversarial training techniques and data augmentation experiments using deep learning models. Specifically, I implemented adversarial training with ResNet on the CIFAR-10 dataset, incorporating adversarial examples generated using Projected Gradient Descent (PGD). By training ResNet18 on both benign and adversarial samples, the goal was to enhance the modelâ€™s robustness against adversarial attacks.

Additionally, I conducted data augmentation experiments using the Flowers dataset, training the model under various augmentation strategies (e.g., Random Horizontal Flip, Random Rotation, ColorJitter) to analyze the impact on model performance and generalizability. I trained the models over different epochs and documented the effects on both benign and adversarial test accuracy, as well as the associated losses.


Link:
https://drive.google.com/drive/folders/1Rh9uORZHQiiBqOYwrv3SCJFQ2SDphpzd?usp=sharing

Please request access to see trained PyTorch models and datasets
